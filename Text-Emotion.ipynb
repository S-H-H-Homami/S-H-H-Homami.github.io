{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the Dataset and look at it briefly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- arrggh kids that won't settle....need some K...</td>\n",
       "      <td>fear and worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- blood and mucus and he chokes and has to swa...</td>\n",
       "      <td>joy and happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- Gig was awesome! Am exahausted and so dont w...</td>\n",
       "      <td>joy and happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- God i'm up early. Hayley still asleep but to...</td>\n",
       "      <td>joy and happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- had a great time at the 'block party' - so d...</td>\n",
       "      <td>fear and worry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              label\n",
       "0  - arrggh kids that won't settle....need some K...     fear and worry\n",
       "1  - blood and mucus and he chokes and has to swa...  joy and happiness\n",
       "2  - Gig was awesome! Am exahausted and so dont w...  joy and happiness\n",
       "3  - God i'm up early. Hayley still asleep but to...  joy and happiness\n",
       "4  - had a great time at the 'block party' - so d...     fear and worry"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"D:\\\\Python\\\\DA-ML\\\\Project\\\\emotion-labels-text.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32422, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32422 entries, 0 to 32421\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    32422 non-null  object\n",
      " 1   label   32422 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 506.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy and happiness    13202\n",
       "fear and worry       10711\n",
       "sadness               6698\n",
       "anger                 1811\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PreProcessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub(r'(\\s)?@\\w+', r'\\1',text)\n",
    "    text=re.sub('\\[.*?\\]','',text)\n",
    "    text=re.sub('[%s]'%re.escape(string.punctuation),'',text)\n",
    "    text=re.sub('\\w*\\d\\w*','',text)\n",
    "    text=re.sub('[''\"\",,,]','',text)\n",
    "    text=re.sub('\\n','',text)\n",
    "    return text\n",
    "\n",
    "cleaned1=lambda x:clean_text(x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the texts from irrelevant characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arrggh kids that wont settleneed some kava fo...</td>\n",
       "      <td>fear and worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blood and mucus and he chokes and has to swal...</td>\n",
       "      <td>joy and happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gig was awesome am exahausted and so dont wan...</td>\n",
       "      <td>joy and happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>god im up early hayley still asleep but today...</td>\n",
       "      <td>joy and happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>had a great time at the block party  so did m...</td>\n",
       "      <td>fear and worry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              label\n",
       "0   arrggh kids that wont settleneed some kava fo...     fear and worry\n",
       "1   blood and mucus and he chokes and has to swal...  joy and happiness\n",
       "2   gig was awesome am exahausted and so dont wan...  joy and happiness\n",
       "3   god im up early hayley still asleep but today...  joy and happiness\n",
       "4   had a great time at the block party  so did m...     fear and worry"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']=pd.DataFrame(data.text.apply(cleaned1))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "tokenizer=ToktokTokenizer()\n",
    "stopword_list=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the words which add no special meaning to the texts (such as \"a\", \"an\", \"the\", ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arrggh kids wont settleneed kava liam thatll s...</td>\n",
       "      <td>fear and worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blood mucus chokes swallow mirth cut short wro...</td>\n",
       "      <td>joy and happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gig awesome exahausted dont want revise boo hoo</td>\n",
       "      <td>joy and happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>god im early hayley still asleep today party d...</td>\n",
       "      <td>joy and happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great time block party mackenzie</td>\n",
       "      <td>fear and worry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              label\n",
       "0  arrggh kids wont settleneed kava liam thatll s...     fear and worry\n",
       "1  blood mucus chokes swallow mirth cut short wro...  joy and happiness\n",
       "2    gig awesome exahausted dont want revise boo hoo  joy and happiness\n",
       "3  god im early hayley still asleep today party d...  joy and happiness\n",
       "4                   great time block party mackenzie     fear and worry"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']=pd.DataFrame(data.text.apply(remove_stopwords))\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[\"text\"]\n",
    "y=data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train , y_test=train_test_split(X,y, test_size=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for best classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7935643055412769\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf =  Pipeline([('tfidf', TfidfVectorizer()), \n",
    "                  ('classifier',DecisionTreeClassifier(random_state = 30, max_depth=10,splitter='best'))])\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "acc_score = clf.score(y_test,y_preds)\n",
    "print(acc_score)\n",
    "scores['DecisionTreeClassifier']=acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6335972036599157\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "lr= Pipeline([('tfidf', TfidfVectorizer()), \n",
    "                  ('classifier',LogisticRegression(random_state=30))])\n",
    "lr.fit(X_train,y_train)\n",
    "y_preds = lr.predict(X_test)\n",
    "acc_lr_score = lr.score(y_test,y_preds)\n",
    "print(acc_lr_score)\n",
    "scores['LogisticRegression']=acc_lr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6188958568931839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=Pipeline([('tfidf', TfidfVectorizer()), \n",
    "                  ('classifier',RandomForestClassifier(random_state=30))])\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "y_preds=rf.predict(X_test)\n",
    "acc_score = rf.score(y_test,y_preds)\n",
    "print(acc_score)\n",
    "scores['RandomForestClassifier']=acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - KNeighborsClassifier: 0.557\n",
      "Accuracy Score - KNeighborsClassifier: 0.5810630204585175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model=Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('classifier',KNeighborsClassifier())])\n",
    "\n",
    "\n",
    "mlp=model.fit(X_train,y_train)\n",
    "y_preds = clf.predict(X_test)\n",
    "        \n",
    "print (f'Accuracy - KNeighborsClassifier: {mlp.score(X_train,y_train):.3f}')\n",
    "acc_score = mlp.score(y_test,y_preds)\n",
    "print(f'Accuracy Score - KNeighborsClassifier: {acc_score}')\n",
    "\n",
    "scores['KNeighborsClassifier']=acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.22491170\n",
      "Validation score: 0.566520\n",
      "Iteration 2, loss = 0.90959142\n",
      "Validation score: 0.595154\n",
      "Iteration 3, loss = 0.66501405\n",
      "Validation score: 0.624229\n",
      "Iteration 4, loss = 0.49354496\n",
      "Validation score: 0.618502\n",
      "Iteration 5, loss = 0.38982293\n",
      "Validation score: 0.609251\n",
      "Iteration 6, loss = 0.32324115\n",
      "Validation score: 0.607048\n",
      "Iteration 7, loss = 0.27862291\n",
      "Validation score: 0.601322\n",
      "Iteration 8, loss = 0.24753397\n",
      "Validation score: 0.603965\n",
      "Iteration 9, loss = 0.22361628\n",
      "Validation score: 0.595595\n",
      "Iteration 10, loss = 0.20545896\n",
      "Validation score: 0.592952\n",
      "Iteration 11, loss = 0.19139849\n",
      "Validation score: 0.585463\n",
      "Iteration 12, loss = 0.17961036\n",
      "Validation score: 0.584141\n",
      "Iteration 13, loss = 0.17017106\n",
      "Validation score: 0.581057\n",
      "Iteration 14, loss = 0.16125757\n",
      "Validation score: 0.582379\n",
      "Validation score did not improve more than tol=0.010000 for 10 consecutive epochs. Stopping.\n",
      "Accuracy - MLPClassifier: 0.831\n",
      "Accuracy Score - MLPClassifier: 0.4422740824509098\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model=Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('classifier',MLPClassifier( solver='adam',learning_rate=\"adaptive\", verbose=True, \n",
    "                    max_iter=200, early_stopping=True, n_iter_no_change=10, \n",
    "                    alpha=0.001, momentum=0.5, tol=0.01, random_state=30))])\n",
    "\n",
    "\n",
    "mlp=model.fit(X_train,y_train)\n",
    "y_preds = clf.predict(X_test)\n",
    "        \n",
    "print (f'Accuracy - MLPClassifier: {mlp.score(X_train,y_train):.3f}')\n",
    "acc_score = mlp.score(y_test,y_preds)\n",
    "print(f'Accuracy Score - MLPClassifier: {acc_score}')\n",
    "\n",
    "scores['MLPClassifier']=acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DecisionTreeClassifier': 0.7451423871697337, 'LogisticRegression': 0.6388403413179808, 'RandomForestClassifier': 0.6319522977279737, 'KNeighborsClassifier': 0.5810630204585175, 'MLPClassifier': 0.4422740824509098}\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning hyperparameters for LogisticRegression and RandomForest, in order to check if they get any better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n",
    "tv_X_train=tv.fit_transform(X_train)\n",
    "tv_X_test=tv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "parameters={'penalty':['l1','l2', 'none'],\n",
    "            'C':[0.01,1,10],\n",
    "            'solver':['lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "            }\n",
    "\n",
    "model=LogisticRegression()\n",
    "clf=GridSearchCV(model, parameters, verbose=True, n_jobs=-1)\n",
    "best_clf=clf.fit(tv_X_train,y_train)\n",
    "y_preds = best_clf.predict(tv_X_test)\n",
    "\n",
    "print (f'Best Model for Logistic Regression : {best_clf.best_estimator_}')\n",
    "        \n",
    "print (f'Accuracy - Logistic Regression: {best_clf.score(tv_X_train,y_train):.3f}')\n",
    "acc_score = accuracy_score(y_test,y_preds)\n",
    "\n",
    "print(f'Accuracy Score - LogisticRegression: {acc_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'criterion':['gini', 'entropy'],\n",
    "            'max_depth':[10,5,20],\n",
    "            'max_features':['sqrt', 'log2']}\n",
    "\n",
    "model=RandomForestClassifier()\n",
    "clf=GridSearchCV(model, parameters, verbose=True, n_jobs=-1)\n",
    "best_clf=clf.fit(tv_X_train,y_train)\n",
    "y_preds = best_clf.predict(tv_X_test)\n",
    "\n",
    "print (f'Best Model for RandomForestClassifier : {best_clf.best_estimator_}')\n",
    "        \n",
    "print (f'Accuracy - RandomForestClassifier: {best_clf.score(tv_X_train,y_train):.3f}')\n",
    "\n",
    "acc_score = accuracy_score(y_test,y_preds)\n",
    "print(f'Accuracy Score - RandomForestClassifier: {acc_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - LogisticRegression: 0.410\n",
      "Accuracy Score - LogisticRegression: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('classifier',LogisticRegression(C=0.01, penalty='l1', solver='saga'))])\n",
    "\n",
    "\n",
    "LogReg=model.fit(X_train,y_train)\n",
    "y_preds = LogReg.predict(X_test)\n",
    "        \n",
    "print (f'Accuracy - LogisticRegression: {LogReg.score(X_train,y_train):.3f}')\n",
    "acc_score = LogReg.score(y_test,y_preds)\n",
    "print(f'Accuracy Score - LogisticRegression: {acc_score}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like LogisticRegression is over fitted. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,  561,    0],\n",
       "       [   0,    0, 3240,    0],\n",
       "       [   0,    0, 3905,    0],\n",
       "       [   0,    0, 2021,    0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - RandomForestClassifier: 0.417\n",
      "Accuracy Score - RandomForestClassifier: 0.9922895034440218\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('classifier',RandomForestClassifier(max_depth=10))])\n",
    "\n",
    "\n",
    "RF=model.fit(X_train,y_train)\n",
    "y_preds = RF.predict(X_test)\n",
    "        \n",
    "print (f'Accuracy - RandomForestClassifier: {RF.score(X_train,y_train):.3f}')\n",
    "acc_score = RF.score(y_test,y_preds)\n",
    "print(f'Accuracy Score - RandomForestClassifier: {acc_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    3  558    0]\n",
      " [   0   60 3180    0]\n",
      " [   0    2 3903    0]\n",
      " [   0   10 2011    0]]\n"
     ]
    }
   ],
   "source": [
    "cnfsn_mtrx= confusion_matrix(y_test, y_preds)\n",
    "print(cnfsn_mtrx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of them has a terrible confusion matrices!\n",
    "trying another classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7935643055412769\n",
      "[[  31  493   31    6]\n",
      " [   0 2924  247   69]\n",
      " [   0 2572 1317   16]\n",
      " [   0 1730  158  133]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf =  Pipeline([('tfidf', TfidfVectorizer()), \n",
    "                  ('classifier',DecisionTreeClassifier(random_state = 30, max_depth=10,splitter='best'))])\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "acc_score = clf.score(y_test,y_preds)\n",
    "print(acc_score)\n",
    "cnfsn_mtrx= confusion_matrix(y_test, y_preds)\n",
    "print(cnfsn_mtrx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering all the tests and tries, I choose LogisticRegression with default hyperparameters for my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6335972036599157\n",
      "[[ 232  179  101   49]\n",
      " [   3 2014  830  393]\n",
      " [   4  572 3209  120]\n",
      " [  17  849  447  708]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr= Pipeline([('tfidf', TfidfVectorizer()), \n",
    "                  ('classifier',LogisticRegression(random_state=30))])\n",
    "lr.fit(X_train,y_train)\n",
    "y_preds = lr.predict(X_test)\n",
    "acc_lr_score = lr.score(y_test,y_preds)\n",
    "print(acc_lr_score)\n",
    "scores['LogisticRegression']=acc_lr_score\n",
    "cnfsn_mtrx= confusion_matrix(y_test, y_preds)\n",
    "print(cnfsn_mtrx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best confusion matrix, we got so far!\n",
    "Let's save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "with open('D:\\\\Python\\\\DA-ML\\\\Project\\\\Winner_Model.pkl', 'wb') as f:\n",
    "    pickle.dump(lr, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "531690e4f5184c0260f6cd54203e217f3ff30f38c7672a0d7c213f358cc99e57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
